{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import logging\n",
    "import girder_client\n",
    "import large_image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from imageio import imread\n",
    "\n",
    "from skimage import measure\n",
    "from skimage import segmentation\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "# Need to pull things like API key from a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=os.path.join('..', '.env'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from histomicstk.annotations_and_masks.annotation_and_mask_utils import (\n",
    "    parse_slide_annotations_into_table,\n",
    "    get_image_from_htk_response # Given a girder response, get np array image\n",
    ") \n",
    "\n",
    "from histomicstk.annotations_and_masks.masks_to_annotations_handler import (\n",
    "    get_annotation_documents_from_contours # Converts a contour table into a set of annotation docs for uploading\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constatnts\n",
    "\n",
    "# Directories\n",
    "LOGGING_DIR = os.path.join('..', 'logs')\n",
    "DATA_DIR = os.path.join('..', 'data')\n",
    "LABEL_DIR = os.path.join('..', 'data', 'roi_labels')\n",
    "INTERIM_DIR = os.path.join(DATA_DIR, 'roi_labels_binary')\n",
    "\n",
    "# Server Info\n",
    "APIURL = os.getenv('APIURL')\n",
    "APIKEY = os.getenv('APIKEY')\n",
    "COLLECTION_NAME = os.getenv('COLLECTION_NAME')\n",
    "FOLDER_NAME = os.getenv('FOLDER_NAME')\n",
    "\n",
    "# Files\n",
    "ROI_DATA_PATH = os.path.join(DATA_DIR, 'notes_on_data.xlsx')\n",
    "GTCODE_PATH = os.path.join(DATA_DIR, 'gt_codes.csv')\n",
    "LOG_PATH = os.path.join(LOGGING_DIR, 'histomics_upload_rois.log')\n",
    "\n",
    "# Constant values\n",
    "RESIZE_FRACTION = 0.1\n",
    "\n",
    "# Verification\n",
    "if not os.path.exists(LOGGING_DIR):\n",
    "    os.makedirs(LOGGING_DIR)\n",
    "\n",
    "if not os.path.exists(INTERIM_DIR):\n",
    "    os.makedirs(INTERIM_DIR)\n",
    "    \n",
    "if not os.path.exists(DATA_DIR):\n",
    "    error(f\"Data directory does not exist at {DATA_DIR}, please create and populate with the labelmaps, ROI-to-WSI spreadsheet, and GT Codes file. Aborting!\")\n",
    "\n",
    "if not os.path.exists(LABEL_DIR):\n",
    "    error(f\"Label directory does not exist at {LABEL_DIR}, please download the ground truth labelmaps (pngs) from Box. Aborting!\")\n",
    "\n",
    "if not os.path.exists(ROI_DATA_PATH):\n",
    "    error(f\"ROI file does not exist at {ROI_DATA_PATH}, please download the ROI-to-WSI dataset from Box. Aborting!\")\n",
    "\n",
    "if not os.path.exists(GTCODE_PATH):\n",
    "    error(f\"GT Codes file does not exist at {GTCODE_PATH}, please create the GT Codes spreadsheet or download from Box. Aborting!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging -- experimental\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\n",
    "                    datefmt='%m-%d %H:%M',\n",
    "                    filename=LOG_PATH,\n",
    "                    filemode='w')\n",
    "\n",
    "# Set up logging to console / notebook output\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')\n",
    "console.setFormatter(formatter)\n",
    "logging.getLogger('').addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_object_boundaries(img_bin):\n",
    "    '''Extract the boundaries of each unique object in the binary image.\n",
    "    \n",
    "    Returns a list of objects as well as centroid points.\n",
    "    '''\n",
    "    img_labels = measure.label(img_bin)\n",
    "    img_props = measure.regionprops(img_labels)\n",
    "    \n",
    "    # Build the sat centroids output\n",
    "    obj_centroids = []\n",
    "    for img_prop in img_props:\n",
    "        obj_centroids.append(img_prop.centroid)\n",
    "    \n",
    "    # Get the list of labels for this class\n",
    "    objs = np.unique(img_labels)\n",
    "    \n",
    "    obj_bounds = []\n",
    "\n",
    "    for obj in objs[1:]:\n",
    "        # Grab a binary image containing only the current object\n",
    "        this_obj = img_labels == obj\n",
    "\n",
    "        # Pad by 1 -- need to operate correctly at the boundaries\n",
    "        this_obj = np.pad(this_obj, 1, 'constant', constant_values=0)\n",
    "\n",
    "        cnt = plt.contour(this_obj)\n",
    "        pts = cnt.collections[0].get_paths()[0].vertices\n",
    "\n",
    "        obj_bounds.append(pts)\n",
    "    \n",
    "    return (obj_centroids, obj_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the pandas dataframe\n",
    "roi_df = pd.read_excel(ROI_DATA_PATH, sheet_name='region_of_interest key')\n",
    "\n",
    "# Drop any row that has NaN in the important columns\n",
    "roi_df.dropna(subset=['corresponding_wsi_number', 'top', 'left'], inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "roi_df.drop(columns=['roi_number_modified', 'notes', 'wsi_uploaded_histomics'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEBUGGING\n",
    "roi_df = roi_df.loc[roi_df.corresponding_wsi_number=='OCC-02-0008-01Z-01-O01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the external info for the ground truth classes and check it\n",
    "GTCodes_df = pd.read_csv(GTCODE_PATH)\n",
    "GTCodes_df.index = GTCodes_df.loc[:, 'group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTCodes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with the server\n",
    "gc = girder_client.GirderClient(apiUrl=APIURL)\n",
    "gc.authenticate(apiKey=APIKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting at the \"collection\" level, walk through the structure to find the target sample id number\n",
    "# that corresponds to the sample name given above.\n",
    "# We assume that there are no nested folders -- it goes collection / folder_list / item_list\n",
    "# If this changes in future, we'll need to update the script\n",
    "collection_list = gc.listCollection()\n",
    "for collection in collection_list:\n",
    "    if collection['name'] == COLLECTION_NAME:\n",
    "        collection_id = collection['_id']\n",
    "\n",
    "folder_list = gc.listFolder(collection_id, parentFolderType='collection')\n",
    "for folder in folder_list:\n",
    "    if folder['name'] == FOLDER_NAME:\n",
    "        folder_id = folder['_id']\n",
    "\n",
    "item_list = gc.listItem(folder_id)\n",
    "\n",
    "# Create a list of all item ids that match this folder and their associated names\n",
    "id_list = []\n",
    "sample_list = []\n",
    "for item in item_list:\n",
    "    id_list.append(item['_id'])\n",
    "    sample_list.append(item['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histomics_img_from_bb(gc, sample_id, roi_left, roi_right, roi_top, roi_bottom):\n",
    "    # Construct the REST API query string that we'll use to pull the image ROI\n",
    "    getStr = f\"item/{sample_id}/tiles/region?\"+ \\\n",
    "        f\"left={roi_left}&\"+ \\\n",
    "        f\"right={roi_right}&\"+ \\\n",
    "        f\"top={roi_top}&\"+ \\\n",
    "        f\"bottom={roi_bottom}\"\n",
    "\n",
    "    # Get the image ROI from histomics server\n",
    "    resp = gc.get(getStr, jsonResp=False)\n",
    "    img_roi = get_image_from_htk_response(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt_annotation_exists(slide_annotations):\n",
    "    \"\"\"Iterates through a slide annotations response, returns True if any of the annotations have a name that starts with 'groundtruth'.\"\"\"\n",
    "\n",
    "    ann_names = []\n",
    "    for annidx, ann in enumerate(slide_annotations):\n",
    "        ann_names.append(ann['annotation']['name'])\n",
    "\n",
    "    if any([x.startswith('groundtruth_') for x in ann_names]):\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out the list of rois associated with each valid row in the spreadsheet\n",
    "# c = 0\n",
    "for sample in roi_df.itertuples():\n",
    "    \n",
    "    sample_name = sample.corresponding_wsi_number + '.tiff'\n",
    "\n",
    "    # Set up logger for this sample\n",
    "    this_log = logging.getLogger(f'{sample_name}')\n",
    "    \n",
    "    this_log.info(f\"Beginning Processing\")\n",
    "    \n",
    "    # Grab the id number corresponding to the current sample_name\n",
    "    sample_id = id_list[sample_list.index(sample_name)]\n",
    "    \n",
    "    # Check to see if the current image has any annotations that already exist\n",
    "    slide_annotations = gc.get('/annotation/item/' + sample_id)\n",
    "    if len(slide_annotations) > 0:\n",
    "        this_log.debug(f\"Found {len(slide_annotations)} annotations\")\n",
    "        \n",
    "        # If so, check to see whether this set of annotations includes a \"ground truth\"\n",
    "        if gt_annotation_exists(slide_annotations):\n",
    "            this_log.warning(f\"Found existing ground truth, so skipping.\")\n",
    "            continue\n",
    "\n",
    "#     # Grab the image ROI from histomics -- only necessary for display and verification\n",
    "#     sample_img = get_histomics_img_from_bb(gc, sample_id, int(sample.left), int(sample.left+sample.width), int(sample.top), int(sample.top+sample.height))\n",
    "#     plt.imshow(sample_img)\n",
    "#     plt.show()\n",
    "\n",
    "#     c = c + 1\n",
    "#     if c > 2: \n",
    "#         break\n",
    "        \n",
    "    # Find the path to the corresponding ROI label, check that there is one\n",
    "    label_path = os.path.join(LABEL_DIR, sample.roi_number_orig+'.png')\n",
    "    if not os.path.exists(label_path):\n",
    "        this_log.warning(f\"Labelmap {sample.roi_number_orig} does not exist at {label_path}, please check. Skipping.\")\n",
    "        continue\n",
    "    else:\n",
    "        this_log.info(f\"Found labelmap at {label_path}\")\n",
    "    \n",
    "    # If we've found a labelmap, and we haven't found an existing ground truth, then process the ROI to obtain our ground truth\n",
    "    \n",
    "    # First, do we need to extract the binary labelmaps? If so, flag it.\n",
    "    # We do the flagging first (this is fast) so we only load the labelmap once (slow) if ANY of the labelmaps are absent.\n",
    "    extract_bin_flags = {}\n",
    "    create_bin_flag = False\n",
    "    for gt_group in GTCodes_df['group']:\n",
    "        extract_bin_flags[gt_group] = False\n",
    "        \n",
    "        bin_path = os.path.join(INTERIM_DIR, sample.roi_number_orig+'_'+gt_group+'.png')\n",
    "        \n",
    "        if not os.path.exists(bin_path):\n",
    "            extract_bin_flags[gt_group] = True\n",
    "            create_bin_flag = True\n",
    "    \n",
    "    # If we have to extract ANY of the ground truth maps, load the image\n",
    "    if create_bin_flag:\n",
    "        this_log.info(f\"Beginning label extraction for {label_path}\")\n",
    "        \n",
    "        img = Image.open(label_path)\n",
    "        w, h = img.size\n",
    "        \n",
    "        # Original image shape\n",
    "        # Resize the image to make analysis easier / faster\n",
    "        img = img.resize((int(w*RESIZE_FRACTION), int(h*RESIZE_FRACTION)), Image.NEAREST)\n",
    "        img = np.array(img)\n",
    "        img = np.uint8(img)\n",
    "        \n",
    "        # Separate the image labelmap into its channels\n",
    "        img_red = img[:, :, 0]\n",
    "        img_green = img[:,:,1]\n",
    "        img_blue = img[:,:,2]\n",
    "        \n",
    "        # Cycle through the groups, and pull out binary images as necessary\n",
    "        for gt_group in GTCodes_df['group']:\n",
    "            if extract_bin_flags[gt_group]:\n",
    "                \n",
    "                # Parse the color of this group\n",
    "                label_rgb = GTCodes_df.loc[gt_group, 'color']\n",
    "                rgb_color = label_rgb.split('rgb(')[1][:-1].split(',')\n",
    "                img_bin = (img_red == int(rgb_color[0])) & (img_green == int(rgb_color[1])) & (img_blue == int(rgb_color[2]))\n",
    "                \n",
    "                # Save this binary image\n",
    "                bin_path = os.path.join(INTERIM_DIR, sample.roi_number_orig+'_'+gt_group+'.png')\n",
    "                mpimg.imsave(bin_path, img_bin)\n",
    "\n",
    "                # Run the extraction of tumor boundaries -- this takes awhile\n",
    "                this_log.info(f\"Beginning extraction of object boundaries for {gt_group}\")\n",
    "                obj_centroids, obj_bounds = extract_object_boundaries(img_bin)\n",
    "                \n",
    "                obj_path = os.path.join(INTERIM_DIR, sample.roi_number_orig+'_'+gt_group+'_bounds.npz')\n",
    "                \n",
    "                # Save the object centroids and boundaries\n",
    "                # Use ** syntax with a dictionary to unpack keys as variable names\n",
    "                # See: https://stackoverflow.com/questions/26427666/use-variables-as-key-names-when-using-numpy-savez\n",
    "                np.savez_compressed(obj_path, **{\n",
    "                    gt_group+'_centroids': obj_centroids, \n",
    "                    gt_group+'_bounds': obj_bounds} )\n",
    "    \n",
    "    \n",
    "        \n",
    "    # Begin conversion to Histomics\n",
    "    group = []\n",
    "    color = []\n",
    "    ymin = []\n",
    "    ymax = []\n",
    "    xmin = []\n",
    "    xmax = []\n",
    "    has_holes = []\n",
    "    touches_edge_top = []\n",
    "    touches_edge_left = []\n",
    "    touches_edge_bottom = []\n",
    "    touches_edge_right = []\n",
    "    coords_x = []\n",
    "    coords_y = []\n",
    "\n",
    "    # Now that we've extracted the boundaries, load up the npz and adjust the coordinates\n",
    "    for gt_group in GTCodes_df['group']:\n",
    "        obj_path = os.path.join(INTERIM_DIR, sample.roi_number_orig+'_'+gt_group+'_bounds.npz')\n",
    "        gt_data_load = np.load(obj_path, allow_pickle=True)\n",
    "        \n",
    "        # Ok stop being generic, let's just call it tumor and satellite\n",
    "        if gt_group == 'satellite':\n",
    "            obj_bounds = gt_data_load['satellite_bounds']\n",
    "            obj_centroids = gt_data_load['satellite_centroids']\n",
    "        if gt_group == 'tumor':\n",
    "            obj_bounds = gt_data_load['tumor_bounds']\n",
    "            obj_centroids = gt_data_load['tumor_centroids']\n",
    "        \n",
    "        for obj in obj_bounds:\n",
    "            obj_x = obj[:,0]\n",
    "            obj_y = obj[:,1]\n",
    "            \n",
    "            obj_x_str = ','.join([str(int(x / RESIZE_FRACTION)) for x in obj_x[::3]])\n",
    "            obj_y_str = ','.join([str(int(y / RESIZE_FRACTION)) for y in obj_y[::3]])\n",
    "\n",
    "            group.append(gt_group)\n",
    "            color.append(GTCodes_df.loc[gt_group, 'color'])\n",
    "            ymin.append(int(np.min(obj_y)))\n",
    "            xmin.append(int(np.min(obj_x)))\n",
    "            ymax.append(int(np.max(obj_y)))\n",
    "            xmax.append(int(np.max(obj_x)))\n",
    "\n",
    "            has_holes.append(0)\n",
    "            touches_edge_top.append(0)\n",
    "            touches_edge_left.append(0)\n",
    "            touches_edge_bottom.append(0)\n",
    "            touches_edge_right.append(0)\n",
    "\n",
    "            coords_x.append(obj_x_str)\n",
    "            coords_y.append(obj_y_str)\n",
    "            \n",
    "    # Put it all into a dataframe\n",
    "    contours_df = pd.DataFrame({\n",
    "        'group': group,\n",
    "        'color': color,\n",
    "        'ymin': ymin,\n",
    "        'ymax': ymax, \n",
    "        'xmin': xmin,\n",
    "        'xmax': xmax,\n",
    "        'has_holes': has_holes,\n",
    "        'touches_edge-top': touches_edge_top, \n",
    "        'touches_edge-left': touches_edge_left,\n",
    "        'touches_edge-bottom': touches_edge_bottom,\n",
    "        'touches_edge-right': touches_edge_right,\n",
    "        'coords_x': coords_x,\n",
    "        'coords_y': coords_y\n",
    "    })\n",
    "    \n",
    "    # Create the annotation \"document\", aka the JSON object that will be pushed to the server\n",
    "    # Here's where we set up the offsets (top and left coords) plus the (non-color) display properties\n",
    "\n",
    "    annprops = {\n",
    "        'X_OFFSET': sample.left,\n",
    "        'Y_OFFSET': sample.top,\n",
    "        'opacity': 0.2,\n",
    "        'lineWidth': 4.0,\n",
    "    }\n",
    "\n",
    "    annotation_docs = get_annotation_documents_from_contours(\n",
    "        contours_df.copy(), \n",
    "        separate_docs_by_group=True, \n",
    "        annots_per_doc=10,\n",
    "        docnamePrefix='groundtruth', \n",
    "        annprops=annprops,\n",
    "        verbose=False, \n",
    "        monitorPrefix=sample_name + \": annotation docs\")\n",
    "\n",
    "    this_log.info(f\"Posting Annotation\")\n",
    "    \n",
    "    # Post the annotation documents you created to the server\n",
    "    for annotation_doc in annotation_docs:\n",
    "        resp = gc.post(\n",
    "            \"/annotation?itemId=\" + sample_id, json=annotation_doc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_table = parse_slide_annotations_into_table(slide_annotations)\n",
    "annotation_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want, display the binary images here to ensure you've got the right classes\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.imshow(img_tumor, cmap=plt.cm.gray)\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.imshow(img_satellites, cmap=plt.cm.gray)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the dataframe for the object annotations you're going to work with\n",
    "# This structure follows the HistomicsTK info here: https://digitalslidearchive.github.io/HistomicsTK/examples/masks_to_annotations_handler.html\n",
    "# TODO: Convert this into a function that parses through all classes\n",
    "\n",
    "group = []\n",
    "color = []\n",
    "ymin = []\n",
    "ymax = []\n",
    "xmin = []\n",
    "xmax = []\n",
    "has_holes = []\n",
    "touches_edge_top = []\n",
    "touches_edge_left = []\n",
    "touches_edge_bottom = []\n",
    "touches_edge_right = []\n",
    "coords_x = []\n",
    "coords_y = []\n",
    "\n",
    "# Satellite groups First\n",
    "for sat in sat_bounds:\n",
    "    sat_x = sat[:,0]\n",
    "    sat_y = sat[:,1]\n",
    "\n",
    "    sat_x_str = ','.join([str(int(x)) for x in sat_x[::3]])\n",
    "    sat_y_str = ','.join([str(int(y)) for y in sat_y[::3]])\n",
    "    \n",
    "    group.append('satellite')\n",
    "    color.append(GTCodes_df.loc['satellite', 'color'])\n",
    "    ymin.append(int(np.min(sat_y)))\n",
    "    xmin.append(int(np.min(sat_x)))\n",
    "    ymax.append(int(np.max(sat_y)))\n",
    "    xmax.append(int(np.max(sat_x)))\n",
    "    \n",
    "    has_holes.append(0)\n",
    "    touches_edge_top.append(0)\n",
    "    touches_edge_left.append(0)\n",
    "    touches_edge_bottom.append(0)\n",
    "    touches_edge_right.append(0)\n",
    "    \n",
    "    coords_x.append(sat_x_str)\n",
    "    coords_y.append(sat_y_str)\n",
    "\n",
    "# Satellite groups First\n",
    "for obj in tum_bounds:\n",
    "    c_x = obj[:,0]\n",
    "    c_y = obj[:,1]\n",
    "\n",
    "    obj_x_str = ','.join([str(int(x)) for x in c_x[::3]])\n",
    "    obj_y_str = ','.join([str(int(y)) for y in c_y[::3]])\n",
    "    \n",
    "    group.append('tumor')\n",
    "    color.append(GTCodes_df.loc['tumor', 'color'])\n",
    "    ymin.append(int(np.min(c_y)))\n",
    "    xmin.append(int(np.min(c_x)))\n",
    "    ymax.append(int(np.max(c_y)))\n",
    "    xmax.append(int(np.max(c_x)))\n",
    "    \n",
    "    has_holes.append(0)\n",
    "    touches_edge_top.append(0)\n",
    "    touches_edge_left.append(0)\n",
    "    touches_edge_bottom.append(0)\n",
    "    touches_edge_right.append(0)\n",
    "    \n",
    "    coords_x.append(obj_x_str)\n",
    "    coords_y.append(obj_y_str)\n",
    "\n",
    "# Put it all into a dataframe\n",
    "contours_df = pd.DataFrame({\n",
    "    'group': group,\n",
    "    'color': color,\n",
    "    'ymin': ymin,\n",
    "    'ymax': ymax, \n",
    "    'xmin': xmin,\n",
    "    'xmax': xmax,\n",
    "    'has_holes': has_holes,\n",
    "    'touches_edge-top': touches_edge_top, \n",
    "    'touches_edge-left': touches_edge_left,\n",
    "    'touches_edge-bottom': touches_edge_bottom,\n",
    "    'touches_edge-right': touches_edge_right,\n",
    "    'coords_x': coords_x,\n",
    "    'coords_y': coords_y\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the annotation \"document\", aka the JSON object that will be pushed to the server\n",
    "# Here's where we set up the offsets (top and left coords) plus the (non-color) display properties\n",
    "\n",
    "annprops = {\n",
    "    'X_OFFSET': roi_left,\n",
    "    'Y_OFFSET': roi_top,\n",
    "    'opacity': 0.2,\n",
    "    'lineWidth': 4.0,\n",
    "}\n",
    "\n",
    "annotation_docs = get_annotation_documents_from_contours(\n",
    "    contours_df.copy(), \n",
    "    separate_docs_by_group=True, \n",
    "    annots_per_doc=10,\n",
    "    docnamePrefix='groundtruth', \n",
    "    annprops=annprops,\n",
    "    verbose=True, \n",
    "    monitorPrefix=SAMPLE_NAME + \": annotation docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post the annotation documents you created to the server\n",
    "for annotation_doc in annotation_docs:\n",
    "    resp = gc.post(\n",
    "        \"/annotation?itemId=\" + sample_id, json=annotation_doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
